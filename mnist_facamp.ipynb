{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom IPython import get_ipython\nget_ipython().run_line_magic('matplotlib','inline')\nimport copy\nimport sys,os\nimport matplotlib.pyplot as plt\nfrom IPython import display\nfrom collections import OrderedDict\nimport time\n#from torch\nimport torch\nfrom torch import nn\nimport torch.optim as optim\nfrom torch.autograd import Variable\nfrom torch.optim import lr_scheduler\n\n#from torchvision\nimport torchvision\nfrom torchvision import transforms\nfrom torchvision.utils import make_grid\nfrom torch.utils.data import Dataset, DataLoader\n#from sklearn.model_selection import train_test_split\nimport torch.nn.functional as F\nfrom torch.utils.data import TensorDataset\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"use_gpu = torch.cuda.is_available()\nprint(\"usando gpu:\", use_gpu)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"import pandas as pd\nsample_submission = pd.read_csv(\"../input/digit-recognizer/sample_submission.csv\")\ntest = pd.read_csv(\"../input/digit-recognizer/test.csv\")\ntrain = pd.read_csv(\"../input/digit-recognizer/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Train shape:', train.shape)\nprint('Test shape:', test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sys.path","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class MEUMNIST(Dataset):\n    def __init__(self, file_path, transform=None):\n        self.data = pd.read_csv(file_path)\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, index):\n        image = self.data.iloc[index, 1:].values.astype(np.uint8).reshape((28, 28, 1))\n        label = self.data.iloc[index, 0]\n        \n        if self.transform is not None:\n            image = self.transform(image)\n            \n        return image, label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.1307,),(0.3081,))\n])\n\ndatasets = {\n        'train': MEUMNIST('../input/digit-recognizer/train.csv', transform=data_transform),\n        'test':  MEUMNIST('../input/digit-recognizer/test.csv', transform=data_transform),\n\n}\n\ntrain_loader = DataLoader(\n    MEUMNIST('../input/digit-recognizer/train.csv', \n             transform=data_transform),\n             batch_size=40, shuffle=True, num_workers=4)\n\ntest_loader = DataLoader(\n    MEUMNIST('../input/digit-recognizer/test.csv', \n             transform=data_transform),\n             batch_size=40, shuffle=True, num_workers=4)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_batch, labels = next(iter(train_loader))\nprint(labels.shape)\nprint(image_batch.shape)\nprint(labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid = torchvision.utils.make_grid(image_batch, normalize=True, pad_value=1.0,padding=1)\nplt.figure(figsize=(20,10))\nplt.imshow(grid.numpy().transpose(1,2,0))\nplt.axis(\"off\")\nplt.title(\"Numeros\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataloaders = {'train': torch.utils.data.DataLoader(datasets['train'],\n                                                            batch_size=100,\n                                                            shuffle=True, num_workers=4),\n               'test': torch.utils.data.DataLoader(datasets['train'],\n                                                            batch_size=100,\n                                                            shuffle=True, num_workers=4), }\n\ndatasets_sizes = {x: len(datasets[x]) for x in ['train', 'test']} #, 'val']}\n\nprint('Tamanho do conjunto de treinamento:', datasets_sizes['train'])\nprint('Tamanho do conjunto de teste:', datasets_sizes['test'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1,32,3,1)\n        self.conv2 = nn.Conv2d(32,64,3,1)\n        self.dropout1 = nn.Dropout2d(0.25)\n        self.dropout2 = nn.Dropout2d(0.5)\n        self.fc1 = nn.Linear(9216,128)\n        self.fc2 = nn.Linear(128,10)\n        \n    def forward(self, x):\n        x = self.conv1(x)\n        x - F.relu(x)\n        x = self.conv2(x)\n        x = F.max_pool2d(x,2)\n        x = self.dropout1(x)\n        x = torch.flatten(x,1)\n        x = self.fc1(x)\n        x = F.relu(x)\n        x = self.dropout2(x)\n        x = self.fc2(x)\n        output = F.log_softmax(x, dim =1)\n        return output\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"use_cuda = torch.cuda.is_available()\ndevice = torch.device(\"cuda\" if use_cuda else \"cpu\")\n\nmodel = Net().to(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"losses = []\ndef train(model,device, train_loader, optimizer, epoch):\n    model.train()\n    dataset_size = len(train_loader.dataset)\n    for batch_idx, (data, target) in enumerate(train_loader):\n        #Preparacao\n        data = data.to(device)\n        target = target.to(device)\n        optimizer.zero_grad()\n        #Feed forward da rede\n        output = model(data)\n        #Calculo do erro\n        loss = F.nll_loss(output, target) # Negative lof likelihood loss\n        #backpropafgation\n        loss.backward()\n        optimizer.step()\n        #print\n        batch_size = len(data)\n        number_of_batches = len(train_loader)\n        current_loss = loss.item()\n        if batch_idx % 100 ==0:\n           # losses.append(loss.item())\n            losses.append(loss.cpu().data.item())\n            print(\"Train Epoch: %d [ %d/%d (%.0f%%)]\\tLoss: %.6f\"%(\n                epoch+1,batch_idx * batch_size, dataset_size,\n                100.0 * batch_idx/number_of_batches, current_loss))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def test(model,device, test_loader):\n    model.eval()\n    test_loss = 0\n    correct = 0 \n    with torch.no_grad():\n        for data, target in test_loader:\n            data, target = data.to(device), target.to(device)\n            output = model(data)\n            \n            test_loss += F.nll_loss(output,target, reduction = 'sum').item()\n            pred = output.argmax(dim=1, keepdim=True)\n            correct += pred.eq(target.view_as(pred)).sum().item()\n          \n    test_loss /= len(test_loader.dataset)\n\n    print('test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%\\n'.format(\n    test_loss,correct,len(test_loader.dataset),\n    100. * correct / len(test_loader.dataset)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"    optimizer = optim.Adadelta(model.parameters(), lr=0.1)\n    scheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.7)\n\n    n_epochs = 10\n    for epoch in range(0, n_epochs):\n        train(model, device, dataloaders['train'], optimizer, epoch)\n        test(model,device,dataloaders['test'])\n        scheduler.step()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(losses)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp_dataloader = torch.utils.data.DataLoader(datasets['train'],\n                                             batch_size=28000,\n                                             shuffle=True, num_workers=0)\nimage_batch, labels = next(iter(temp_dataloader))\n\nimage_batch = image_batch.to(device)\nexample_output = model.forward(image_batch)\n_,y_hat = torch.max(example_output,1)\n\nx = image_batch.cpu().detach().numpy()\n\nw=2\nh=2\nfig=plt.figure(figsize=(12,10))\ncolumns =2\nrows = 2\n\nfor i in range(2, columns*rows +1):\n    fig.add_subplot(rows, columns,i)\n    plt.imshow(x[i,0].reshape(28,28),interpolation='nearest',cmap='gray')\n    plt.colorbar()\n    output = y_hat[i].cpu().numpy()\n    print(output)\n    \nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = torch.Tensor.cpu(y_hat).detach().numpy()\nimage_id = np.arange(1, len(y) + 1)\n\nresult = np.hstack((image_id.reshape((-1, 1)), y.reshape(-1,1)))\nfinal_output = pd.DataFrame(result, columns=['ImageId', 'Label'])\n\nfinal_output.to_csv(path_or_buf =\"submission.csv\", index=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_output","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}